{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Técnicas de Escolha de Modelo em Machine Learning: Separação em Treino/Teste e Validação Cruzada\n",
    "\n",
    "## 1. Separação em Treino e Teste\n",
    "\n",
    "A separação em treino e teste é uma técnica básica para avaliar o desempenho de um modelo de machine learning. A ideia é dividir o conjunto de dados em duas partes:\n",
    "\n",
    "- **Conjunto de treino**: Usado para treinar o modelo, ou seja, para ajustar os parâmetros do modelo com base nos dados disponíveis.\n",
    "- **Conjunto de teste**: Usado para avaliar o desempenho do modelo em dados não vistos durante o treinamento, medindo sua capacidade de generalização.\n",
    "\n",
    "### **Como funciona**:\n",
    "- O conjunto de dados é dividido em uma proporção fixa, como 70% para treino e 30% para teste, ou 80/20.\n",
    "- O modelo é treinado usando os dados de treino.\n",
    "- Após o treinamento, o modelo é testado nos dados de teste para calcular métricas como acurácia, precisão, recall ou F1-score.\n",
    "\n",
    "### **Vantagens**:\n",
    "- Simples e rápido de implementar.\n",
    "- Funciona bem para conjuntos de dados grandes.\n",
    "\n",
    "### **Desvantagens**:\n",
    "- A avaliação pode ser sensível à divisão inicial dos dados.\n",
    "- Não fornece informações robustas sobre a variabilidade do desempenho do modelo.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Validação Cruzada (Cross-Validation)\n",
    "\n",
    "A validação cruzada é uma técnica mais robusta para avaliar modelos. Ela busca reduzir a dependência de uma única divisão dos dados, fornecendo uma avaliação mais confiável.\n",
    "\n",
    "### **Como funciona**:\n",
    "1. O conjunto de dados é dividido em **k** partes (ou folds).\n",
    "2. O modelo é treinado em $k-1$ partes (folds de treino) e testado na parte restante (fold de validação).\n",
    "3. O processo é repetido $k$ vezes, cada vez usando um fold diferente como conjunto de validação.\n",
    "4. Os resultados (métricas de desempenho) de cada iteração são então combinados, geralmente pela média.\n",
    "\n",
    "### **Tipos de validação cruzada**:\n",
    "- **k-fold cross-validation**:\n",
    "  - Divide os dados em $k$ partes de tamanhos aproximadamente iguais.\n",
    "  - Recomendado quando os dados são suficientemente grandes.\n",
    "- **Leave-One-Out Cross-Validation (LOOCV)**:\n",
    "  - Cada exemplo no conjunto de dados é usado como conjunto de teste uma vez.\n",
    "  - Muito preciso, mas computacionalmente caro para conjuntos de dados grandes.\n",
    "- **Stratified k-fold cross-validation**:\n",
    "  - Garante que a proporção de classes nos folds é a mesma que no conjunto de dados original.\n",
    "  - Importante em problemas de classificação com classes desbalanceadas.\n",
    "\n",
    "### **Vantagens**:\n",
    "- Fornece uma avaliação confiável do modelo.\n",
    "- Usa os dados de forma eficiente, pois todos os exemplos são usados para treino e validação.\n",
    "- Ajuda a detectar overfitting e underfitting.\n",
    "\n",
    "### **Desvantagens**:\n",
    "- Computacionalmente mais caro do que a simples separação em treino e teste.\n",
    "- Pode ser desafiador implementar para conjuntos de dados muito grandes ou modelos complexos.\n",
    "\n",
    "---\n",
    "\n",
    "## Comparação: Treino/Teste vs Validação Cruzada\n",
    "\n",
    "| Característica              | Treino/Teste                 | Validação Cruzada             |\n",
    "|-----------------------------|-----------------------------|-------------------------------|\n",
    "| **Facilidade de Implementação** | Muito simples              | Um pouco mais complexo         |\n",
    "| **Avaliação do Modelo**       | Menos confiável             | Mais confiável e robusta       |\n",
    "| **Uso de Dados**             | Menos eficiente (testa apenas uma vez) | Mais eficiente (testa várias vezes) |\n",
    "| **Custo Computacional**      | Baixo                      | Médio a alto                  |\n",
    "\n",
    "---\n",
    "\n",
    "## Quando usar cada técnica:\n",
    "\n",
    "- **Separação em treino e teste**:\n",
    "  - Ideal para experimentos rápidos.\n",
    "  - Quando o conjunto de dados é muito grande e o impacto da divisão é pequeno.\n",
    "  \n",
    "- **Validação cruzada**:\n",
    "  - Essencial para conjuntos de dados menores.\n",
    "  - Útil em problemas onde a confiabilidade na avaliação é crítica.\n",
    "  - Para modelos que demandam uma avaliação detalhada antes de entrar em produção.\n",
    "\n",
    "Se a validação cruzada for computacionalmente cara, estratégias como usar uma validação cruzada com um menor número de folds ($k$) podem ajudar a balancear custo e qualidade da avaliação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nested Cross-Validation Scores: [0.96666667 0.96666667 0.93333333 1.         1.        ]\n",
      "Média dos scores: 0.9733333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Carregar os dados\n",
    "data = load_iris()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Criar o modelo\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Configurar grid search\n",
    "param_grid = {'max_depth': [3, 5, 10]}\n",
    "grid = GridSearchCV(DecisionTreeClassifier(), param_grid, cv=3)\n",
    "\n",
    "# Configurar nested cross-validation\n",
    "scores = cross_val_score(grid, X, y, cv=5)\n",
    "\n",
    "print(f\"Nested Cross-Validation Scores: {scores}\")\n",
    "print(f\"Média dos scores: {scores.mean()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
