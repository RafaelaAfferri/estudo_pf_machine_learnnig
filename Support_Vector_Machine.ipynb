{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine (SVM) e Como Usá-los com Scikit-Learn\n",
    "\n",
    "## O que é SVM?\n",
    "O **Support Vector Machine (SVM)** é um algoritmo de aprendizado supervisionado utilizado principalmente para problemas de **classificação**, mas também pode ser aplicado a **regressão** e **detecção de anomalias**. O principal objetivo do SVM é encontrar o **hiperplano** que melhor separa as classes em um espaço de características.\n",
    "\n",
    "### Como Funciona o SVM?\n",
    "O SVM busca o hiperplano que maximiza a **margem** entre as classes, ou seja, a distância entre os pontos mais próximos de cada classe e o hiperplano. Esses pontos são chamados de **vetores de suporte**.\n",
    "\n",
    "Quando os dados não são linearmente separáveis, o SVM utiliza o **truque do kernel**, que mapeia os dados para um espaço de dimensão superior onde as classes podem ser separadas.\n",
    "\n",
    "#### Tipos de Kernel:\n",
    "Os principais tipos de kernel usados no SVM são:\n",
    "- **Linear**: para dados linearmente separáveis.\n",
    "- **Polinomial**: para problemas com fronteiras de decisão complexas.\n",
    "- **RBF (Radial Basis Function)**: o mais usado para problemas não-lineares.\n",
    "- **Sigmoid**: utilizado ocasionalmente, mas menos comum.\n",
    "\n",
    "### Diferença entre Soft SVM e Hard SVM\n",
    "\n",
    "A diferença entre **Soft SVM** (Máquina de Vetores de Suporte Suave) e **Hard SVM** (Máquina de Vetores de Suporte Rígida) está no tratamento dos dados de treinamento que não são linearmente separáveis.\n",
    "\n",
    "#### 1. Hard SVM:\n",
    "- O **Hard SVM** assume que os dados são **linearmente separáveis**, ou seja, existem dois conjuntos de dados que podem ser separados por uma única linha ou hiperplano (em dimensões superiores).\n",
    "- Ele tenta encontrar o **hiperplano de separação** com a maior margem possível, sem permitir nenhum erro de classificação. Isso significa que nenhum ponto de dados pode estar do lado errado do hiperplano.\n",
    "- Esse modelo é muito restritivo, pois em muitos casos os dados do mundo real não são perfeitamente separáveis, e o **Hard SVM** pode falhar em encontrar uma solução útil se houver ruído ou dados sobrepostos.\n",
    "\n",
    "#### 2. Soft SVM:\n",
    "- O **Soft SVM** é uma versão mais flexível, projetada para **lidar com dados não linearmente separáveis**. Em vez de forçar uma separação perfeita, ele permite que alguns pontos de dados **sejam classificados incorretamente**, introduzindo **erro de classificação**.\n",
    "- Isso é feito através de uma função de penalização que adiciona uma **função de custo** para cada erro. O modelo ainda tenta maximizar a margem entre as classes, mas com uma **tolerância** para erros.\n",
    "- O parâmetro de regularização \\(C\\) controla o trade-off entre **maximizar a margem** e **minimizar os erros** de classificação: um valor grande de \\(C\\) faz o modelo mais rígido (mais erros são penalizados fortemente), enquanto um valor pequeno de \\(C\\) permite mais flexibilidade e erros, favorecendo a margem maior.\n",
    "\n",
    "#### Resumo das diferenças:\n",
    "- **Hard SVM**: Não permite erros de classificação, exige que os dados sejam perfeitamente separáveis.\n",
    "- **Soft SVM**: Permite erros de classificação, ajustando-se melhor a dados reais e não linearmente separáveis, com o parâmetro \\(C\\) controlando a flexibilidade.\n",
    "\n",
    "O **Soft SVM** é o modelo mais utilizado na prática, pois ele pode lidar melhor com dados do mundo real, onde nem sempre é possível encontrar uma separação perfeita entre as classes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função de Custo e Função de Penalização\n",
    "\n",
    "Em aprendizado de máquina, as **funções de custo** e **funções de penalização** são componentes fundamentais para treinar modelos. Elas ajudam a guiar o processo de otimização, permitindo que o modelo aprenda a partir dos dados e minimize os erros. Vamos detalhar as duas:\n",
    "\n",
    "#### 1. Função de Custo\n",
    "\n",
    "A **função de custo** (ou função objetivo) é uma medida de quão bom ou ruim é o desempenho do modelo com relação aos dados de treinamento. Ela calcula o erro entre as previsões do modelo e os valores reais. O objetivo do treinamento é **minimizar** essa função de custo para que o modelo faça previsões mais precisas.\n",
    "\n",
    "Em termos simples:\n",
    "- **Função de Custo**: Mede o quão distante a previsão do modelo está da verdade. Quanto menor o valor da função de custo, melhor o modelo.\n",
    "\n",
    "Por exemplo, no caso da **regressão linear**, a função de custo é geralmente o **erro quadrático médio** (MSE - Mean Squared Error), dada por:\n",
    "\n",
    "$$\n",
    "J(\\theta) = \\frac{1}{m} \\sum_{i=1}^{m} (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "\n",
    "Onde:\n",
    "- $y_i$ são os valores reais,\n",
    "- $\\hat{y}_i$ são as previsões do modelo,\n",
    "- $m$ é o número total de dados.\n",
    "\n",
    "Em **classificação**, a função de custo pode ser a **entropia cruzada** (cross-entropy), que mede a diferença entre as distribuições de probabilidade previstas pelo modelo e as distribuições verdadeiras.\n",
    "\n",
    "#### 2. Função de Penalização (Regularização)\n",
    "\n",
    "A **função de penalização** é uma técnica utilizada para evitar que o modelo **overfit** (se ajuste excessivamente aos dados de treinamento), forçando o modelo a ser mais simples e generalizar melhor para dados não vistos. Ela adiciona um \"termo de penalidade\" à função de custo para reduzir a complexidade do modelo.\n",
    "\n",
    "Em modelos como o **SVM** e **regressão linear**, a regularização pode ser aplicada para controlar a **complexidade do modelo**, evitando que ele aprenda padrões que são específicos demais para os dados de treinamento (e que não se generalizam bem para dados novos).\n",
    "\n",
    "Existem duas formas comuns de regularização:\n",
    "\n",
    "#### 2.1 **L1 (Lasso) Regularização**\n",
    "A regularização **L1** adiciona uma penalização baseada na soma dos **valores absolutos** dos coeficientes dos parâmetros do modelo. Ela tende a forçar alguns dos coeficientes a **zero**, o que pode resultar em um modelo mais simples e mais esparso (com menos variáveis).\n",
    "\n",
    "A função de custo com penalização L1 é dada por:\n",
    "\n",
    "$$\n",
    "J(\\theta) = \\frac{1}{m} \\sum_{i=1}^{m} (y_i - \\hat{y}_i)^2 + \\lambda \\sum_{j=1}^{n} |\\theta_j|\n",
    "$$\n",
    "\n",
    "Onde:\n",
    "- $\\lambda$ é o parâmetro de regularização (controle de penalização),\n",
    "- $\\theta_j$ são os coeficientes do modelo.\n",
    "\n",
    "#### 2.2 **L2 (Ridge) Regularização**\n",
    "A regularização **L2** adiciona uma penalização baseada na soma dos **quadrados** dos coeficientes dos parâmetros. Ao contrário da L1, a L2 não força os coeficientes a zero, mas faz com que os valores dos coeficientes sejam pequenos, promovendo um modelo mais suave e menos propenso a overfitting.\n",
    "\n",
    "A função de custo com penalização L2 é dada por:\n",
    "\n",
    "$$\n",
    "J(\\theta) = \\frac{1}{m} \\sum_{i=1}^{m} (y_i - \\hat{y}_i)^2 + \\lambda \\sum_{j=1}^{n} \\theta_j^2\n",
    "$$\n",
    "\n",
    "Onde:\n",
    "- $\\lambda$ controla o quanto de penalização é aplicado.\n",
    "\n",
    "#### 3. Função de Custo + Função de Penalização no SVM (Soft SVM)\n",
    "\n",
    "No contexto do **SVM**, a função de custo está relacionada à **margem de separação** entre as classes, enquanto a função de penalização (ou regularização) ajuda a balancear a margem com a **aceitação de erros**.\n",
    "\n",
    "A função de custo no SVM tenta minimizar a soma das penalizações pelos erros de classificação, ao mesmo tempo em que maximiza a margem entre as classes. Isso é representado pela **função de perda de Hinge**, combinada com um termo de penalização (regularização) $C$.\n",
    "\n",
    "A função de custo para o SVM com regularização é:\n",
    "\n",
    "$$\n",
    "J(\\theta) = \\frac{1}{2} \\|\\theta\\|^2 + C \\sum_{i=1}^{n} \\max(0, 1 - y_i (\\theta \\cdot x_i + b))\n",
    "$$\n",
    "\n",
    "Onde:\n",
    "- $\\|\\theta\\|^2$ é a penalização L2 (típica em SVM),\n",
    "- $C$ é o parâmetro de regularização que controla o trade-off entre a margem e a penalização pelos erros de classificação.\n",
    "\n",
    "#### **Interpretação de $C$**:\n",
    "- **Valor grande de $C$**: O modelo vai priorizar a **ausência de erros** de classificação, o que pode reduzir a margem e tornar o modelo mais suscetível a overfitting.\n",
    "- **Valor pequeno de $C$**: O modelo aceita mais **erros de classificação**, priorizando uma **margem maior** e favorecendo a **generalização**.\n",
    "\n",
    "### Resumo:\n",
    "- **Função de custo**: Mede a diferença entre as previsões do modelo e os valores reais. O objetivo é minimizar esse valor.\n",
    "- **Função de penalização (regularização)**: Adiciona um termo à função de custo para controlar a complexidade do modelo e evitar overfitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Como Usar SVM no Scikit-Learn?\n",
    "A biblioteca `scikit-learn` facilita a implementação de SVM com a classe `SVC` para **classificação** e `SVR` para **regressão**.\n",
    "\n",
    "### Exemplo Prático: Classificação com SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do modelo: 1.00\n",
      "Relatório de Classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       1.00      1.00      1.00        13\n",
      "           2       1.00      1.00      1.00        13\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importando as bibliotecas necessárias\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Carregando um dataset de exemplo\n",
    "data = datasets.load_iris()\n",
    "X = data.data  # Características\n",
    "y = data.target  # Rótulos\n",
    "\n",
    "# Dividindo o dataset em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Criando o modelo SVM com kernel RBF\n",
    "svm_model = SVC(kernel='rbf', C=1, gamma='scale')  # C controla a margem e gamma controla a largura do kernel\n",
    "\n",
    "# Treinando o modelo\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Fazendo previsões\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Avaliando o modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Acurácia do modelo: {accuracy:.2f}\")\n",
    "print(\"Relatório de Classificação:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parâmetros Importantes:\n",
    "- **C**: Controla a penalidade para erros. Valores mais altos de `C` resultam em um modelo com uma margem menor, mas maior precisão no treinamento.\n",
    "- **kernel**: Define o tipo de kernel a ser usado (`linear`, `poly`, `rbf`, `sigmoid`).\n",
    "- **gamma**: Controla a influência de cada ponto de treinamento. Valores mais altos de `gamma` tornam o modelo mais focado nos dados de treinamento, o que pode levar ao overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajuste dos Hiperparâmetros\n",
    "Você pode usar técnicas como `GridSearchCV` para encontrar os melhores valores de `C,` `kernel`, e `gamma`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "[CV] END ..................C=0.1, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.0s\n",
      "Melhores parâmetros: {'C': 1, 'gamma': 'scale', 'kernel': 'poly'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definindo a grade de parâmetros\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': ['scale', 'auto', 0.1, 1],\n",
    "    'kernel': ['linear', 'rbf', 'poly']\n",
    "}\n",
    "\n",
    "# Configurando a busca de grade\n",
    "grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=2)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Melhor modelo\n",
    "print(\"Melhores parâmetros:\", grid.best_params_)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
