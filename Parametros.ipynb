{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precision, Recall, Sensibilidade, Especificidade e Curva ROC\n",
    "\n",
    "Esses conceitos são fundamentais para avaliar o desempenho de modelos de classificação em aprendizado de máquina e estatística. Aqui está uma explicação detalhada:\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Precision (Precisão):**\n",
    "- **Definição:** Mede a proporção de predições positivas corretas em relação a todas as predições positivas feitas pelo modelo.\n",
    "- **Fórmula:**  \n",
    "  $$\n",
    "  \\text{Precision} = \\frac{\\text{True Positives (TP)}}{\\text{True Positives (TP)} + \\text{False Positives (FP)}}\n",
    "  $$\n",
    "- **Interpretação:**  \n",
    "  Se o modelo prevê que algo pertence à classe positiva, a precisão indica a probabilidade de estar certo.  \n",
    "  É útil quando o custo de um **falso positivo** é alto.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Recall (Revocação ou Sensibilidade):**\n",
    "- **Definição:** Mede a proporção de predições positivas corretas em relação a todos os casos positivos reais.\n",
    "- **Fórmula:**  \n",
    "  $$\n",
    "  \\text{Recall} = \\frac{\\text{True Positives (TP)}}{\\text{True Positives (TP)} + \\text{False Negatives (FN)}}\n",
    "  $$\n",
    "- **Interpretação:**  \n",
    "  Indica a capacidade do modelo de identificar corretamente os casos positivos.  \n",
    "  É importante quando o custo de um **falso negativo** é alto (ex.: diagnóstico médico).\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Sensibilidade:**\n",
    "- **Definição:**  \n",
    "  É outro nome para o **recall**. Mede a habilidade do modelo em identificar corretamente os verdadeiros positivos.  \n",
    "  É especialmente relevante em contextos onde **não perder positivos é essencial**.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Especificidade:**\n",
    "- **Definição:** Mede a proporção de predições negativas corretas em relação a todos os casos negativos reais.\n",
    "- **Fórmula:**  \n",
    "  $$\n",
    "  \\text{Especificidade} = \\frac{\\text{True Negatives (TN)}}{\\text{True Negatives (TN)} + \\text{False Positives (FP)}}\n",
    "  $$\n",
    "- **Interpretação:**  \n",
    "  Indica a capacidade do modelo de evitar falsos positivos.  \n",
    "  É importante em contextos onde **rotular algo como positivo incorretamente é problemático**.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Curva ROC (Receiver Operating Characteristic):**\n",
    "- **Definição:** É um gráfico que mostra a relação entre a **sensibilidade (recall)** e a **especificidade** para diferentes limiares de decisão.\n",
    "- **Eixo X:** $1 - \\text{Especificidade}$ (Taxa de Falsos Positivos).  \n",
    "- **Eixo Y:** Sensibilidade (Recall ou Taxa de Verdadeiros Positivos).\n",
    "- **Área sob a curva (AUC):**  \n",
    "  $$\n",
    "  \\text{AUC (Area Under the Curve)}\n",
    "  $$  \n",
    "  Representa a capacidade geral do modelo de separar as classes. Um valor de AUC próximo de 1 indica um bom desempenho, enquanto um valor próximo de 0,5 indica desempenho semelhante ao acaso.\n",
    "\n",
    "- **Interpretação:**  \n",
    "  - Um modelo perfeito terá uma curva que passa pelo canto superior esquerdo (100% de recall e 100% de especificidade).  \n",
    "  - A curva ajuda a entender o desempenho do modelo em diferentes limiares.\n",
    "\n",
    "---\n",
    "\n",
    "## **Exemplo Resumido:**\n",
    "Imagine um modelo que prevê se um paciente tem uma doença:  \n",
    "- **TP:** Paciente doente identificado corretamente.  \n",
    "- **FP:** Paciente saudável identificado como doente.  \n",
    "- **TN:** Paciente saudável identificado corretamente.  \n",
    "- **FN:** Paciente doente identificado como saudável.  \n",
    "\n",
    "### Métricas:\n",
    "- **Precisão:** Quantos dos pacientes identificados como doentes estão realmente doentes?  \n",
    "- **Recall (Sensibilidade):** Quantos pacientes doentes o modelo conseguiu identificar?  \n",
    "- **Especificidade:** Quantos pacientes saudáveis o modelo não classificou erroneamente como doentes?  \n",
    "- **Curva ROC:** Avalia o equilíbrio entre sensibilidade e especificidade para diferentes cenários.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando as bibliotecas necessárias\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix, roc_curve, auc, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Carregando o dataset Iris\n",
    "data = load_iris()\n",
    "X = data.data  # Features\n",
    "y = data.target  # Rótulos (classes)\n",
    "\n",
    "# Dividindo o conjunto de dados em treino e teste (80% treino, 20% teste)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Inicializando o modelo\n",
    "model = LogisticRegression(max_iter=200)\n",
    "\n",
    "# Treinando o modelo\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prevendo as classes do conjunto de teste\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Prevendo as probabilidades para a curva ROC\n",
    "y_score = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "recall = recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "print(\"Specificity:\", specificity)\n",
    "\n",
    "# Curva ROC para cada classe\n",
    "fpr, tpr, _ = roc_curve(y_test, model.predict_proba(X_test)[:, 1], pos_label=1)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(\"ROC AUC:\", roc_auc)\n",
    "\n",
    "# Plotando a curva ROC\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')  # Linha diagonal para referência\n",
    "plt.xlabel('1 - Specificity (False Positive Rate)')\n",
    "plt.ylabel('Sensitivity (True Positive Rate)')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Relatório completo com várias métricas\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusão:\n",
    "O código acima calcula e imprime várias métricas, além de exibir a curva ROC para a classificação, e um relatório completo de desempenho do modelo. A métrica precision e recall será calculada para todas as classes (usando a média 'macro' para lidar com múltiplas classes), e a especificidade será derivada da matriz de confusão.\n",
    "\n",
    "### Importante:\n",
    "- **Precision** e **Recall** podem ser calculados com a média de várias classes (`average='macro'`).\n",
    "- Para múltiplas classes, a curva ROC é gerada para cada classe individualmente. A AUC é a área sob a curva para essa classe.\n",
    "Esse é um exemplo básico usando o Iris dataset. Em problemas do mundo real, os dados e modelos podem ser mais complexos, mas o processo de cálculo das métricas é o mesmo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Média Macro e Média Ponderada para Precision e Recall\n",
    "\n",
    "Quando você calcula **precision** e **recall** para um modelo de classificação com múltiplas classes, é necessário decidir como combinar os valores dessas métricas para obter um valor único. A opção de usar a **média macro** é uma maneira de fazer essa agregação.\n",
    "\n",
    "## Média Macro (Macro Average)\n",
    "\n",
    "A **média macro** calcula a **média simples** das métricas para cada classe, **tratando cada classe igualmente**, independentemente de sua frequência no conjunto de dados. Ou seja, ela não leva em consideração o número de amostras de cada classe, apenas o desempenho do modelo em cada uma delas.\n",
    "\n",
    "### Como funciona?\n",
    "\n",
    "1. **Precision e Recall por classe:**  \n",
    "   Para um problema de classificação com múltiplas classes, o modelo calcula **precision** e **recall** para cada classe individualmente.\n",
    "\n",
    "2. **Média simples de cada classe:**  \n",
    "   Depois, calcula-se a média desses valores de **precision** e **recall** de todas as classes.\n",
    "\n",
    "### Exemplo\n",
    "\n",
    "Considere um modelo de classificação com 3 classes: **Classe A**, **Classe B** e **Classe C**. O modelo pode ter os seguintes valores de **precision** e **recall** para cada classe:\n",
    "\n",
    "- **Classe A:**\n",
    "  - Precision = 0.80\n",
    "  - Recall = 0.75\n",
    "- **Classe B:**\n",
    "  - Precision = 0.90\n",
    "  - Recall = 0.85\n",
    "- **Classe C:**\n",
    "  - Precision = 0.70\n",
    "  - Recall = 0.65\n",
    "\n",
    "A **média macro** seria a média simples desses valores:\n",
    "\n",
    "- **Precision (macro):**\n",
    "  \\[\n",
    "  \\text{Precision}_{\\text{macro}} = \\frac{0.80 + 0.90 + 0.70}{3} = 0.80\n",
    "  \\]\n",
    "\n",
    "- **Recall (macro):**\n",
    "  \\[\n",
    "  \\text{Recall}_{\\text{macro}} = \\frac{0.75 + 0.85 + 0.65}{3} = 0.75\n",
    "  \\]\n",
    "\n",
    "Portanto, a **média macro** para **precision** seria 0.80 e para **recall** seria 0.75.\n",
    "\n",
    "### Vantagens e Desvantagens da Média Macro\n",
    "\n",
    "#### Vantagens:\n",
    "- **Igualdade entre as classes:** A média macro trata todas as classes igualmente, independentemente do seu tamanho no conjunto de dados. Isso é útil quando queremos avaliar o modelo de forma equilibrada, sem que classes majoritárias dominem a métrica.\n",
    "- **Atenção a classes minoritárias:** Se uma classe minoritária for mal classificada, ela será igualmente considerada no cálculo da média macro, destacando a importância do modelo em aprender a distinguir todas as classes.\n",
    "\n",
    "#### Desvantagens:\n",
    "- **Não leva em conta o desequilíbrio das classes:** Como a média macro não pondera as classes com base em sua frequência, ela pode ser menos representativa em cenários onde há um desequilíbrio de classes (por exemplo, quando algumas classes possuem muito mais amostras do que outras).\n",
    "\n",
    "---\n",
    "\n",
    "## Média Ponderada (Weighted Average)\n",
    "\n",
    "Se você quiser levar em consideração o desequilíbrio das classes, pode usar a **média ponderada**. Na média ponderada, as métricas de **precision** e **recall** de cada classe são ponderadas pelo número de amostras dessa classe no conjunto de dados.\n",
    "\n",
    "Por exemplo, se uma classe tem muitas mais amostras do que outra, a média ponderada vai dar mais peso à classe maior, refletindo seu impacto no desempenho do modelo. Isso é útil em cenários de **classes desbalanceadas**.\n",
    "\n",
    "---\n",
    "\n",
    "## Resumo\n",
    "\n",
    "- **Média Macro:** Calcula a média simples das métricas de cada classe, sem considerar o número de amostras em cada classe.\n",
    "- **Média Ponderada:** Calcula a média das métricas, levando em conta o número de amostras em cada classe.\n",
    "\n",
    "Escolher entre média macro ou ponderada depende do tipo de problema que você está enfrentando e da importância relativa que você deseja dar a cada classe no cálculo das métricas.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
