{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropia em Machine Learning\n",
    "\n",
    "Na área de **machine learning** e **ciência de dados**, a entropia é usada para medir a incerteza ou desordem de um conjunto de dados, especialmente em problemas de classificação e construção de árvores de decisão.\n",
    "\n",
    "### Conceito de Entropia\n",
    "Em machine learning, a entropia quantifica o quão misturados estão os dados em relação às suas classes (ou rótulos). \n",
    "\n",
    "- **Entropia Baixa**: Se as classes estão bem separadas e a incerteza é baixa.\n",
    "- **Entropia Alta**: Se as classes estão muito misturadas, tornando difícil prever a qual classe um dado pertence.\n",
    "\n",
    "### Fórmula da Entropia\n",
    "A entropia para um conjunto de dados com classes \\( C_1, C_2, \\ldots, C_n \\) é calculada com a fórmula:\n",
    "\n",
    "$$\n",
    "H(S) = - \\sum_{i=1}^{n} p(C_i) \\log_2 p(C_i)\n",
    "$$\n",
    "\n",
    "onde:\n",
    "- $H(S)$ é a entropia do conjunto $S$,\n",
    "- $p(C_i)$ é a probabilidade de ocorrência da classe $C_i$ no conjunto de dados.\n",
    "\n",
    "### Entropia em Árvores de Decisão\n",
    "Em árvores de decisão, a entropia é utilizada para medir a qualidade de uma divisão (split) dos dados em nós da árvore. O objetivo é escolher divisões que minimizem a entropia, criando nós mais \"puros\" onde os dados pertencem predominantemente a uma única classe.\n",
    "\n",
    "#### Passos do Cálculo\n",
    "1. **Entropia Inicial**: Calcula-se a entropia para o conjunto de dados antes da divisão.\n",
    "2. **Entropia após a Divisão**: A entropia de cada subconjunto é calculada após a divisão, e a entropia total é a média ponderada das entropias dos subconjuntos.\n",
    "3. **Ganho de Informação**: É a redução de entropia alcançada com a divisão. Uma alta redução indica uma divisão eficiente.\n",
    "\n",
    "### Exemplo\n",
    "Imagine um conjunto de dados com 10 exemplos onde a classificação é binária (por exemplo, sim/não):\n",
    "\n",
    "- 5 exemplos são da classe \"sim\"\n",
    "- 5 exemplos são da classe \"não\"\n",
    "\n",
    "A entropia inicial seria:\n",
    "\n",
    "$$\n",
    "H(S) = -\\left(0,5 \\cdot \\log_2(0,5) + 0,5 \\cdot \\log_2(0,5)\\right) = 1\n",
    "$$\n",
    "\n",
    "Se fizermos uma divisão que resulte em subconjuntos com um único rótulo em cada (por exemplo, um nó contendo apenas \"sim\" e outro apenas \"não\"), a entropia desses nós será zero, indicando uma divisão perfeita.\n",
    "\n",
    "### Resumo\n",
    "Em resumo, a entropia em machine learning mede a desordem e é utilizada para selecionar divisões que melhorem a previsibilidade dos dados em árvores de decisão. \n",
    "\n",
    "- **Entropia baixa**: menos incerteza e melhor separação entre classes.\n",
    "- **Entropia alta**: mais incerteza e classes mais misturadas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Nó  Impureza (Entropia)\n",
      "0    0             1.584963\n",
      "1    1             0.000000\n",
      "2    2             1.000000\n",
      "3    3             0.445065\n",
      "4    4             0.146094\n",
      "5    5             0.000000\n",
      "6    6             0.000000\n",
      "7    7             0.918296\n",
      "8    8             0.000000\n",
      "9    9             0.918296\n",
      "10  10             0.000000\n",
      "11  11             0.000000\n",
      "12  12             0.151097\n",
      "13  13             0.918296\n",
      "14  14             0.000000\n",
      "15  15             0.000000\n",
      "16  16             0.000000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "# Carregar o conjunto de dados Iris\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Criar e treinar a árvore de decisão\n",
    "tree = DecisionTreeClassifier(criterion='entropy')\n",
    "tree.fit(X, y)\n",
    "\n",
    "# Acessar as impurezas de cada nó\n",
    "impurezas = tree.tree_.impurity\n",
    "\n",
    "# Mostrar as impurezas em cada nó\n",
    "df_impurezas = pd.DataFrame({\n",
    "    'Nó': range(len(impurezas)),\n",
    "    'Impureza (Entropia)': impurezas\n",
    "})\n",
    "\n",
    "print(df_impurezas)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
